{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slow Diffusion\n",
    "\n",
    "> Image diffusion, trained from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm intrigued by [Stretching Each Dollar: Diffusion Training from Scratch on a Micro-Budget](https://arxiv.org/abs/2407.15811) ([Twitter thread](https://x.com/VSehwag_/status/1815729297606214013)) and will attempt to scale up my FastAI project using their recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote class=\"twitter-tweet\" data-conversation=\"none\"><p lang=\"en\" dir=\"ltr\">Let’s move to training the large scale model. Similar to stable-diffusion, we train in latent space (SDXL VAE) and training in two phases. We first pretrain on 256x256 resolution and then fine tune on 512x512 resolution. Our total training budget was $1,890 (account only gpu cost…</p>&mdash; Vikash Sehwag (@VSehwag_) <a href=\"https://twitter.com/VSehwag_/status/1815729314442220013?ref_src=twsrc%5Etfw\">July 23, 2024</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "pip install slow_diffusion\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
