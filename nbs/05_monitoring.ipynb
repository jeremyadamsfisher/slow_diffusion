{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring\n",
    "\n",
    "> Monitor different aspects of the model and training run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import re\n",
    "from argparse import Namespace\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import lightning as L\n",
    "from glom import glom\n",
    "from torch import nn\n",
    "\n",
    "import wandb\n",
    "from slow_diffusion.fashionmnist import TinyFashionMNISTDataModule\n",
    "from slow_diffusion.training import get_tiny_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "class MonitorCallback(L.Callback):\n",
    "    def __init__(self, /, **gloms):\n",
    "        super().__init__()\n",
    "        if not gloms:\n",
    "            raise ValueError\n",
    "        self.gloms = gloms\n",
    "\n",
    "    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n",
    "        args = Namespace(\n",
    "            trainer=trainer,\n",
    "            pl_module=pl_module,\n",
    "            outputs=outputs,\n",
    "            batch=batch,\n",
    "            batch_idx=batch_idx,\n",
    "        )\n",
    "        for name, spec in self.gloms.items():\n",
    "            self.log(name, glom(args, spec), on_step=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |exports\n",
    "class CountDeadUnitsCallback(L.Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n",
    "        nans = 0\n",
    "        for _, params in pl_module.named_parameters():\n",
    "            nans += params.isnan().int().sum().item()\n",
    "        self.log(\"dead_units\", nans, reduce_fx=sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |exports\n",
    "class Hook:\n",
    "    \"\"\"Wrapper for a PyTorch hook, facilitating adding instance state\"\"\"\n",
    "\n",
    "    def __init__(self, m, f):\n",
    "        self.hook = m.register_forward_hook(partial(f, self))\n",
    "\n",
    "    def remove(self):\n",
    "        self.hook.remove()\n",
    "\n",
    "    def __del__(self):\n",
    "        self.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |exports\n",
    "class ModuleStats:\n",
    "    def __init__(self, label, module):\n",
    "        self.label = label\n",
    "        self.hook = module.register_forward_hook(self.append)\n",
    "\n",
    "    def append(self, module, _, activations):\n",
    "        if not module.training:\n",
    "            return\n",
    "        activations = activations.cpu()\n",
    "        self.log(f\"{label}:mean\", activations.mean().cpu().item())\n",
    "        self.log(f\"{label}:std\", activations.std().cpu().item())\n",
    "\n",
    "    def cleanup(self):\n",
    "        self.hook.remove()\n",
    "\n",
    "\n",
    "class StatsCallback(L.Callback):\n",
    "    def __init__(\n",
    "        self,\n",
    "        mods: list[type[nn.Module]] | None = None,\n",
    "        mod_filter: list[str] | None = None,\n",
    "    ):\n",
    "        assert mods or mod_filter\n",
    "        self.mods = []\n",
    "        if mods is not None:\n",
    "            self.mods.extend(mods)\n",
    "        self.mod_filter = mod_filter\n",
    "        self.mod_stats = []\n",
    "\n",
    "    def on_fit_start(self, trainer, pl_module):\n",
    "        if self.mod_filter is not None:\n",
    "            for name, mod in pl_module.named_modules():\n",
    "                if re.match(self.mod_filter, name):\n",
    "                    self.mods.append(mod)\n",
    "\n",
    "        for i, mod in self.mods:\n",
    "            ms = ModuleStats(f\"layer_{i}\", mod)\n",
    "            self.mod_stats.append(ms)\n",
    "\n",
    "    def cleanup(self):\n",
    "        for hook in self.hooks:\n",
    "            hook.cleanup()\n",
    "\n",
    "    def on_fit_end(self, trainer, pl_module):\n",
    "        self.cleanup()\n",
    "\n",
    "    def on_exception(self, trainer, pl_module, exception):\n",
    "        self.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintLogger(L.pytorch.loggers.logger.DummyLogger):\n",
    "    def log_metrics(self, metrics, step):\n",
    "        print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = TinyFashionMNISTDataModule(32, n_workers=0)\n",
    "dm.setup()\n",
    "model = get_tiny_unet()\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=1,\n",
    "    callbacks=[\n",
    "        MonitorCallback(lr=\"trainer.optimizers.0.param_groups.0.lr\"),\n",
    "        CountDeadUnitsCallback(),\n",
    "        StatsCallback(mod_filter=r\"convs\"),\n",
    "    ],\n",
    "    logger=PrintLogger(),\n",
    ")\n",
    "trainer.fit(model=model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SlowDiffusion",
   "language": "python",
   "name": "slow_diffusion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
