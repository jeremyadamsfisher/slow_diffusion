{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring\n",
    "\n",
    "> Monitor different aspects of the model and training run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeremy/micromamba/envs/slowai/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# |export\n",
    "import re\n",
    "from argparse import Namespace\n",
    "\n",
    "import lightning as L\n",
    "import wandb\n",
    "from glom import glom\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from torch import nn\n",
    "\n",
    "from slow_diffusion.fashionmnist import FashionMNISTDataModule\n",
    "from slow_diffusion.training import get_tiny_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "class MonitorCallback(L.Callback):\n",
    "    def __init__(self, gloms: dict[str, str]):\n",
    "        super().__init__()\n",
    "        if not gloms:\n",
    "            raise ValueError\n",
    "        self.gloms = gloms\n",
    "\n",
    "    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n",
    "        args = Namespace(\n",
    "            trainer=trainer,\n",
    "            pl_module=pl_module,\n",
    "            outputs=outputs,\n",
    "            batch=batch,\n",
    "            batch_idx=batch_idx,\n",
    "        )\n",
    "        for name, spec in self.gloms.items():\n",
    "            self.log(name, glom(args, spec), on_step=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |exports\n",
    "class CountDeadUnitsCallback(L.Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n",
    "        nans = 0\n",
    "        for _, params in pl_module.named_parameters():\n",
    "            nans += params.isnan().int().sum().item()\n",
    "        self.log(\"dead_units\", nans, reduce_fx=sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |exports\n",
    "class Stats:\n",
    "    def __init__(self, label, module):\n",
    "        self.label = label\n",
    "        self.hook = module.register_forward_hook(self.append)\n",
    "\n",
    "    def append(self, module, _, activations):\n",
    "        if not module.training:\n",
    "            return\n",
    "        activations = activations.cpu()\n",
    "        self.log(f\"{self.label}:mean\", activations.mean().cpu().item())\n",
    "        self.log(f\"{self.label}:std\", activations.std().cpu().item())\n",
    "\n",
    "    def cleanup(self):\n",
    "        self.hook.remove()\n",
    "\n",
    "\n",
    "class StatsCallback(L.Callback):\n",
    "    def __init__(\n",
    "        self,\n",
    "        mods: list[type[nn.Module]] | None = None,\n",
    "        mod_filter: str | None = None,\n",
    "    ):\n",
    "        assert mods or mod_filter\n",
    "        self.mods = []\n",
    "        if mods is not None:\n",
    "            self.mods.extend(mods)\n",
    "        self.mod_filter = mod_filter\n",
    "        self.mod_stats = []\n",
    "\n",
    "    def on_fit_start(self, trainer, pl_module):\n",
    "        if self.mod_filter is not None:\n",
    "            for name, mod in pl_module.named_modules():\n",
    "                if re.match(self.mod_filter, name):\n",
    "                    self.mods.append(mod)\n",
    "\n",
    "        for i, mod in self.mods:\n",
    "            s = Stats(f\"layer_{i}\", mod)\n",
    "            self.mod_stats.append(s)\n",
    "\n",
    "    def cleanup(self):\n",
    "        for s in self.mod_stats:\n",
    "            s.cleanup()\n",
    "\n",
    "    def on_fit_end(self, trainer, pl_module):\n",
    "        self.cleanup()\n",
    "\n",
    "    def on_exception(self, trainer, pl_module, exception):\n",
    "        self.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "/home/jeremy/micromamba/envs/slowai/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | unet    | Unet    | 185 M  | train\n",
      "1 | loss_fn | MSELoss | 0      | train\n",
      "--------------------------------------------\n",
      "185 M     Trainable params\n",
      "0         Non-trainable params\n",
      "185 M     Total params\n",
      "742.125   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b2b8cd908145a38c2a8c8ba2526a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeremy/micromamba/envs/slowai/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2709be778b6140518dbc28657f2b100e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                      | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeremy/micromamba/envs/slowai/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "with wandb.init():\n",
    "    wandb_logger = WandbLogger()\n",
    "    dm = FashionMNISTDataModule(256, n_workers=0)\n",
    "    dm.setup()\n",
    "    model = get_tiny_unet()\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=1,\n",
    "        callbacks=[\n",
    "            MonitorCallback({\"lr\": \"trainer.optimizers.0.param_groups.0.lr\"}),\n",
    "            CountDeadUnitsCallback(),\n",
    "            StatsCallback(mod_filter=r\"convs\"),\n",
    "        ],\n",
    "        logger=WandbLogger(),\n",
    "        precision=\"bf16-mixed\",\n",
    "    )\n",
    "    trainer.fit(model=model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slow_diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
