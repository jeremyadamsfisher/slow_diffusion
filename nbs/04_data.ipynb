{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "> Core data functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremiahfisher/miniforge3/envs/slow_diffusion/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| exports\n",
    "import itertools\n",
    "import math\n",
    "import multiprocessing\n",
    "import tempfile\n",
    "from functools import cache\n",
    "\n",
    "import lightning as L\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.transforms.functional as F\n",
    "from datasets import load_dataset\n",
    "from einops import rearrange\n",
    "from torch.utils.data import DataLoader, Dataset, default_collate\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |exporti\n",
    "def show_images(imgs, titles=[], figsize=(4, 4)):\n",
    "    n, *_ = imgs.shape\n",
    "    k = math.ceil(math.sqrt(n))\n",
    "    imgs = rearrange(imgs, \"bs c h w -> bs h w c\")\n",
    "    fig, axes = plt.subplots(k, k, figsize=figsize)\n",
    "    for title, img, ax in itertools.zip_longest(titles, imgs, axes.flatten()):\n",
    "        ax.imshow(img)\n",
    "        if title:\n",
    "            ax.set(title=title)\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noisify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |exports\n",
    "def ᾱ(t, reshape=True):\n",
    "    assert (0 <= t).all() and (t <= 1).all()\n",
    "    ᾱ_ = ((t * math.pi / 2).cos() ** 2).clamp(0.0, 0.999)\n",
    "    if reshape:\n",
    "        ᾱ_ = ᾱ_.reshape(-1, 1, 1, 1)\n",
    "    return ᾱ_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |exports\n",
    "def noisify(x_0, t=None):\n",
    "    n, *_ = x_0.shape\n",
    "    device = x_0.device\n",
    "\n",
    "    if t is None:\n",
    "        t = torch.rand((n,), device=device)\n",
    "\n",
    "    # Sample 2D noise for each example in the batch\n",
    "    ε = torch.randn(x_0.shape, device=device)\n",
    "\n",
    "    # Add noise according to the equation in Algorithm 1, such\n",
    "    # that the variance of the distribution does not change. Also,\n",
    "    # ensure that the overall magnitude does not change by 0-centering\n",
    "    # x_0 and 0.5-centering x_t\n",
    "    x_t = ᾱ(t).sqrt() * (x_0) + (1 - ᾱ(t)).sqrt() * ε\n",
    "\n",
    "    return ((x_t, t), ε)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |exports\n",
    "class DiffusionDataModule:\n",
    "    def __init__(self, hf_ds_uri, noisfy_fn, bs):\n",
    "        self.bs = bs\n",
    "        self.noisfy_fn = noisfy_fn\n",
    "        self.hf_ds_uri = hf_ds_uri\n",
    "\n",
    "    def _collate(self, batch):\n",
    "        x_0 = torch.stack([F.pil_to_tensor(row[\"image\"]) for row in batch])\n",
    "        return self.noisfy_fn(x_0)\n",
    "\n",
    "    def _freeze(self, batch):\n",
    "        x_0 = torch.stack([F.pil_to_tensor(img) for img in batch[\"image\"]])\n",
    "        ((x_t, t), epsilon) = self.noisfy_fn(x_0)\n",
    "        return {\"x_t\": x_t, \"t\": t, \"epsilon\": epsilon}\n",
    "\n",
    "    def _frozen_collate(self, rows):\n",
    "        def s(feature):\n",
    "            return torch.tensor([row[feature] for row in rows])\n",
    "\n",
    "        return (s(\"x_t\"), s(\"t\")), s(\"epsilon\")\n",
    "\n",
    "    def setup(self, stage: str | None = None, test_splits=(\"test\",)):\n",
    "        self.ds = load_dataset(self.hf_ds_uri)\n",
    "        for split in test_splits:\n",
    "            self.ds[split] = self.ds[split].map(\n",
    "                self._freeze,\n",
    "                batched=True,\n",
    "                # We can discard the original data, as we only care about the noised information\n",
    "                remove_columns=self.ds[split].features.keys(),\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.ds[\"train\"],\n",
    "            batch_size=self.bs,\n",
    "            collate_fn=self._collate,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.ds[\"test\"],\n",
    "            batch_size=self.bs,\n",
    "            collate_fn=self._frozen_collate,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slow_diffusion",
   "language": "python",
   "name": "slow_diffusion"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
